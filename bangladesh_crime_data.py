# -*- coding: utf-8 -*-
"""Bangladesh Crime Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I-ZF7Gxp2Op6cLvBeuLyBZ72U4-k2Li3
"""

print("The objective of this analysis is to predict future crime data for various divisions in Bangladesh using historical data from 2010 to 2019. Specifically, we aim to identify which division is predicted to experience the highest increase in crime rates from 2020 to 2030.")

"""**1. Load the Dataset**"""

import pandas as pd

url = '/content/crime_data_bangladesh.csv'  # dataset
data = pd.read_csv(url)

# display first few rows dataset
print(data.head())

"""**2.Data Preprocessing**"""

# missing values
print(data.isnull().sum())

# Drop or fill missing values
data = data.dropna()  # or data.fillna(method='ffill', inplace=True)

# encode the 'area_name' categorical variable
data = pd.get_dummies(data, columns=['area_name'], drop_first=True)

"""**3.Feature Engineering**"""

# Extract features and target variable
X = data.drop(columns=['year'])
y = data['year']

# Normalize numerical features
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X = scaler.fit_transform(X)

"""**4.Train-Test Split**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**5.Model Selection and Training**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Initialize the model
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', mean_squared_error(y_test, y_pred, squared=False))

"""# Forecasting Future Data"""

# Create a range of future years
future_years = range(2020, 2031)

# Prepare an empty DataFrame to store future predictions
future_predictions = []

# Iterate over each city and predict future crime data
for year in future_years:
    future_data = data[data['year'] == data['year'].max()].copy()
    future_data['year'] = year
    future_X = scaler.transform(future_data.drop(columns=['year']))
    future_pred = model.predict(future_X)
    future_data['predicted_year'] = future_pred
    future_predictions.append(future_data)

# Concatenate all future predictions into a single DataFrame
future_predictions_df = pd.concat(future_predictions)

print(future_predictions_df)

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

#  dataset
url = '/content/crime_data_bangladesh.csv'  # Replace with the actual path to your dataset
data = pd.read_csv(url)

# data preprocessing
data = data.dropna()
data = pd.get_dummies(data, columns=['area_name'], drop_first=True)

# extract features and target variable
X = data.drop(columns=['year'])
y = data['year']

# normalize numerical features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# train-Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Selection and Training
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', mean_squared_error(y_test, y_pred, squared=False))

# Forecasting Future Data
future_year = 2030
future_data = data[data['year'] == data['year'].max()].copy()
future_data['year'] = future_year

# Prepare the future data for prediction
future_X = scaler.transform(future_data.drop(columns=['year']))

# Predict future crime data
future_predictions = model.predict(future_X)

# Create a DataFrame for the results
future_data['predicted_year'] = future_predictions

print(future_data)

"""## Visualization"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Load the dataset
url = '/content/crime_data_bangladesh.csv'
data = pd.read_csv(url)

# Data Preprocessing
data = data.dropna()
data = pd.get_dummies(data, columns=['area_name'], drop_first=True)

# Extract features and target variable
X = data.drop(columns=['year'])
y = data['year']

# Normalize numerical features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Selection and Training
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', mean_squared_error(y_test, y_pred, squared=False))

#  range  future years
future_years = range(2020, 2031)

# prepare an empty DataFrame to store future predictions
future_predictions = pd.DataFrame()

# Iterate over each future year and predict crime data
for year in future_years:
    future_data = data[data['year'] == data['year'].max()].copy()
    future_data['year'] = year
    future_X = scaler.transform(future_data.drop(columns=['year']))
    future_data['predicted_year'] = model.predict(future_X)
    future_predictions = pd.concat([future_predictions, future_data])

# Visualization
plt.figure(figsize=(14, 8))
for col in data.columns[1:]:
    sns.lineplot(data=future_predictions, x='year', y=col, label=col)
plt.title('Predicted Crime Data for 2020 to 2030')
plt.xlabel('Year')
plt.ylabel('Crime Count')
plt.legend(title='Crime Types', loc='upper left')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Load the dataset
url = '/content/crime_data_bangladesh.csv'  # Replace with the actual path to your dataset
data = pd.read_csv(url)

# Data Preprocessing
data = data.dropna()
data = pd.get_dummies(data, columns=['area_name'], drop_first=True)

# Extract features and target variable
X = data.drop(columns=['year'])
y = data['year']

# Normalize numerical features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Selection and Training
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', mean_squared_error(y_test, y_pred, squared=False))

# Create a range of future years
future_years = range(2020, 2031)

# Prepare an empty DataFrame to store future predictions
future_predictions = pd.DataFrame()

# Iterate over each future year and predict crime data
for year in future_years:
    future_data = data[data['year'] == data['year'].max()].copy()
    future_data['year'] = year
    future_X = scaler.transform(future_data.drop(columns=['year']))
    future_data['predicted_year'] = model.predict(future_X)
    future_predictions = pd.concat([future_predictions, future_data])

# Calculate the increase in crime rates for each division
division_increase = future_predictions.groupby('year').sum().diff().fillna(0).cumsum()

# Identify the division with the highest increase
highest_increase = division_increase.idxmax(axis=1)
highest_increase_division = highest_increase.value_counts().idxmax()

# Visualization
plt.figure(figsize=(14, 8))
for col in data.columns[1:]:
    sns.lineplot(data=future_predictions, x='year', y=col, label=col)
plt.title('Predicted Crime Data for 2020 to 2030')
plt.xlabel('Year')
plt.ylabel('Crime Count')
plt.legend(title='Crime Types', loc='upper left')
plt.show()

print("The division with the highest increase in crime rate is:", highest_increase_division)